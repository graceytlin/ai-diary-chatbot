{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COM3029 Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will aim to deliver a chatbot that will act as a conversational diary. The user will be able to add entries to their own digital diary through natural conversation with the chatbot. Additionally, the chatbot will allow the user to request details regarding previous entries in the diary. Each user will be able to be personally identifiable to the chatbot by providing the chatbot with their name and a special phrase or word that will unlock their diary information.\n",
    "\n",
    "The diary will store user information regarding places they visited, people they met and how they felt that day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1- Model Serving Decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Serving Options**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches were researched for serving the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Model embedded in the app*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model embedding is the most direct way to use a model in the application. By embedding the file that contains the model in the the application code. The application can directly interact with it. This is a simple infrastructure as it easy to set up and allows for offline use. However this is not a very scalable approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Model served as an API***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to model embedding is wrapping a binary file around a microservice that includes features to make the model accessable to applications.\n",
    "\n",
    "This when we can use a pickle or a dump of the python object of the model than can then be deserialised and exposed to an endpoint for applications to interact with.\n",
    "\n",
    "This means that despite the complexity of the model it can be saved and loaded in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use serve the model as an API as it is a simple approach that we had experience with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **API Considerations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we wanted to deliver the project in such a way that it follows a realistic deployment process that would appropriate for the delivery of a production level application. \n",
    "\n",
    "Various model serving using an API approach will be explored to determine the best way to deliver the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Django***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Django is a very well known framework for making full-stack web applications. It uses the REST framework to expose endpoints to clients. The REST framework includes enpoints GET and POST which can be used to send client requests to host.\n",
    "\n",
    "However high perfomance can be diffcult to achieve as it has a significantly larger codebase than other solutions we explore. It also has a monolithic work flow that can complicate things  as Django also includes too many functions that are not necessary for a simple project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***FastAPI***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAPI is a fast, high performance web framework that allows developers to build API's using python.\n",
    "\n",
    "It is a good approach to use as it is offers a great approach creating scalable products. It also provides an alternative to REST in GraphQL.\n",
    "\n",
    "While REST is the de-facto standard for web APIs. It can cause request overfetching when multiple endpoints are created.\n",
    "\n",
    "GraphQL instead, is a query language that uses one endpoint and the retun values is dependent on client requests.\n",
    "\n",
    "As our project only used at most two endpoints, GraphQL was not considered as necessary for our process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Flask***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask is another web framework that can be classified as a micro-framework.\n",
    "\n",
    "It is a light-weight approach that allows for simple protoypes to be made that enables rapid development. It is also easily extended to cover many use cases such as serving models from an endpoint. It uses REST to create endpoints for client requests to the server. Flask is considered the most policed and feature-rich micro framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Bottle***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottle is similar to Flask. The main difference to Flask is that it is only a wrapper around a server. It is not as extensible as Flask nor does it scale to include other modules that Flask can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we decided to use REST API for creating our endpoints, we chose Flask as out API framework as we found that it very easy to setup and develop on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "class STATE(Enum):\n",
    "    GREETING = auto()\n",
    "    RUNNING=auto()\n",
    "    ASKED_NAME=auto()\n",
    "    QUIT=auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "state = 0\n",
    "def get_response(url,data):\n",
    "    response = requests.post(url,json=data)\n",
    "    print(response.text)\n",
    "    response = json.loads(response.text)\n",
    "    return response[\"response\"], response[\"state\"]\n",
    "\n",
    "def format_bot_response(response):\n",
    "    print(\"Bot: {}\".format(response))\n",
    "\n",
    "data={\"msg\":None}\n",
    "response, state= get_response('http://localhost:5000/start_greeting',data)\n",
    "format_bot_response(response)\n",
    "\n",
    "\n",
    "while state !=-1:\n",
    "    data[\"msg\"]=input(\"User: \")\n",
    "    response, state= get_response('http://localhost:5000/get_response',data)\n",
    "    format_bot_response(response)\n",
    "\n",
    "print(\"Client closed\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c18d149b1430996ab208b97416b2929d11b8b835656007a7ca35232ab6bc079f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
