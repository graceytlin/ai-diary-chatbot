{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **COM3029 Group Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will aim to deliver a chatbot that will act as a conversational diary. The user will be able to add entries to their own digital diary through natural conversation with the chatbot. Additionally, the chatbot will allow the user to request details regarding previous entries in the diary. Each user will be able to be personally identifiable to the chatbot by providing the chatbot with their name and a special phrase or word that will unlock their diary information.\n",
    "\n",
    "The diary will store user information regarding places they visited, people they met and how they felt that day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q1- Model Serving Decisions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Serving Options**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches were researched for serving the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Model embedded in the app*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model embedding is the most direct way to use a model in the application. By embedding the file that contains the model in the the application code. The application can directly interact with it. This is a simple infrastructure as it easy to set up and allows for offline use. However this is not a very scalable approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Model served as an API***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to model embedding is wrapping a binary file around a microservice that includes features to make the model accessable to applications. This when we can use a pickle or a dump of the python object of the model than can then be deserialised and exposed to an endpoint for applications to interact with. This means that despite the complexity of the model it can be saved and loaded in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to use serve the model as an API as it is a simple approach that we had experience with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **API Considerations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project we wanted to deliver the project in such a way that it follows a realistic deployment process that would appropriate for the delivery of a production level application. \n",
    "\n",
    "Various model serving using an API approach will be explored to determine the best way to deliver the application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Django***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Django is a very well known framework for making full-stack web applications. It uses the REST framework to expose endpoints to clients. The REST framework includes enpoints GET and POST which can be used to send client requests to host.\n",
    "\n",
    "However high perfomance can be diffcult to achieve as it has a significantly larger codebase than other solutions we explore. It also has a monolithic work flow that can complicate things  as Django also includes too many functions that are not necessary for a simple project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***FastAPI***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastAPI is a fast, high performance web framework that allows developers to build API's using python.\n",
    "\n",
    "It is a good approach to use as it is offers a great approach creating scalable products. It also provides an alternative to REST in GraphQL.\n",
    "\n",
    "While REST is the de-facto standard for web APIs. It can cause request overfetching when multiple endpoints are created.\n",
    "\n",
    "GraphQL instead, is a query language that uses one endpoint and the retun values is dependent on client requests.\n",
    "\n",
    "As our project only used at most two endpoints, GraphQL was not considered as necessary for our process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Flask***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flask is another web framework that can be classified as a micro-framework.\n",
    "\n",
    "It is a light-weight approach that allows for simple protoypes to be made that enables rapid development. It is also easily extended to cover many use cases such as serving models from an endpoint. It uses REST to create endpoints for client requests to the server. Flask is considered the most policed and feature-rich micro framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***Bottle***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bottle is similar to Flask. The main difference to Flask is that it is only a wrapper around a server. It is not as extensible as Flask nor does it scale to include other modules that Flask can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we decided to use REST API for creating our endpoints, we chose Flask as out API framework as we found that it very easy to setup and develop on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q2- Web Service and Architectural Choices**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Architectural Considerations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Intent Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main intent classifier determines what the user wants to do with the Chatbot. The following intents are use to determine both the state of the chatbot and the response of the Chatbot:\n",
    "\n",
    "* \n",
    "* \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Sentiment Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wanted to develop the chatbot to be able to classify user diary entries by the following emotions:\n",
    "\n",
    "* happiness\n",
    "* sad\n",
    "* anxious\n",
    "* angry\n",
    "* neutral\n",
    "\n",
    "We did this by ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Named Entity Recognition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Transformers' [NERModel](https://simpletransformers.ai/docs/ner-model/) was used to train our name entity recognition component. The [conll2003](https://huggingface.co/datasets/conll2003) dataset as it focuses on language independednt named entity recognition which we found performed well for out chatbot domain where users may have non English names. As most of the data in conll2003 is from newspapers, we were able to extract date and time tokens, re-label them and train the model on. The model itself is a pretrained model of BERT (bert-based-cased). We found that this had a high accuracy in entity recognition and allowed returned preditions that were easy to process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dialog Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to implement a heuristics approach for our Dialog flow as it performed better than other attempts with AI models. Our dialogue for our chatbot is controlled by a state machine that can use the intent classfier to determine a state change. The flow of the dialog can be viewed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add image for flow diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the Flask app, run the command \"python build_and_run.py\" in terminal.\n",
    "\n",
    "Requirements:\n",
    "Python Version: 3.9.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](flask_app_running.png \"Flask app running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q3- Basic Functionality Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the Flask server is running, a client can then send REST requests to the app to interact with the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "data = {}\n",
    "counter = 0\n",
    "\n",
    "def get_response(url,data):\n",
    "    response = requests.post(url,json=data)\n",
    "    response = json.loads(response.text)\n",
    "    return response[\"response\"], response[\"state\"]\n",
    "\n",
    "def format_bot_response(response):\n",
    "    print(\"Bot: {}\".format(response))\n",
    "\n",
    "data={\"msg\":None}\n",
    "response, state= get_response('http://localhost:5000/start_greeting',data)\n",
    "format_bot_response(response)\n",
    "\n",
    "\n",
    "while state >0:\n",
    "    data[\"msg\"]=input()\n",
    "    print(\"User: \"+data[\"msg\"])\n",
    "    response, state= get_response('http://localhost:5000/get_response',data)\n",
    "    format_bot_response(response)\n",
    "    if response[-8:] == \"Goodbye!\":\n",
    "        break\n",
    "\n",
    "print(\"Client closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q4- Performance of Chatbot**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q5- Basic Monitoring Capability**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q6- CI/CD Build and Deployment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Q7- Recording**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recording can be found in the submission folder: "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c18d149b1430996ab208b97416b2929d11b8b835656007a7ca35232ab6bc079f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
